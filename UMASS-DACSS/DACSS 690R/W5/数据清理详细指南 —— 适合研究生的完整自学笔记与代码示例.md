### 数据清理详细指南 —— 适合研究生的完整自学笔记与代码示例

#### 讲师：Jose Manuel Magallanes Reyes

---

### 课程背景及学习目标

- **数据清理的重要性**：数据清理是数据科学和机器学习项目中的重要环节，未清理的数据会影响分析结果的准确性。数据清理不仅是简单的格式化，还包括数据一致性、完整性检查，以及识别和处理可能影响数据质量的潜在问题。
- **学习目标**：
  - 了解数据清理的基本流程，掌握系统化的清理方法。
  - 掌握处理常见数据问题（如缺失值、不一致格式等）的具体步骤。
  - 通过在 Python 中使用清理工具（如 Pandas）实现高效的数据预处理。

---

### 数据清理的核心步骤

数据清理是一个系统性的流程，可以分为以下几个关键步骤：

1. **初步查看数据**：了解数据的整体结构，发现明显的异常。
2. **理解数据字典**：明确各个字段的含义和数据类型。
3. **处理数据源特性**：解决区域配置、格式差异等问题。
4. **数据结构标准化**：确保唯一标识和字段命名一致。
5. **数据内容清理**：移除多余字符、格式化文本、处理分类数据。
6. **缺失值处理**：针对缺失值的合理填充或删除。
7. **类型转换与规范**：确保数据类型正确、便于分析。

---

### 数据清理步骤与代码详解

#### 1. 初步查看数据

**初步检查目的**：在数据分析的第一步，使用 `.head()` 和 `.tail()` 方法检查数据的前几行和后几行，这样可以快速了解数据结构和异常值。

**示例代码**：
```python
import pandas as pd

# 读取 CSV 文件
df = pd.read_csv('data.csv')

# 查看数据前5行
print(df.head())

# 查看数据后5行
print(df.tail())
```

通过初步查看，我们可以发现潜在的格式问题或异常数据值，如缺失值、重复列、格式不规范的内容等。可以将这些发现记录下来，逐步解决。

#### 2. 理解数据字典和字段定义

数据字典是理解数据的关键，包含字段的定义、数据来源和取值含义。理解数据的含义有助于确保清理过程中不会误删或误改重要数据。

- **数据字典的作用**：数据字典包含了字段的名称和含义、可能的取值和数据的统计特征。例如，字段 `regime_type` 可能包括“full democracy”或“authoritarian regime”，如果不理解其含义，可能会误将某些值删除或替换。

**查看数据字典**：
假设数据字典以 JSON 文件提供，其中包含字段名称和定义：

```python
import json

# 读取数据字典
with open('data_dictionary.json') as f:
    data_dict = json.load(f)

# 输出特定字段的定义
print("Field 'regime_type':", data_dict['regime_type'])
```

#### 3. 数据源特性检查与区域配置

数据来源和格式可能因地区而异，例如日期格式（MM-DD-YYYY 或 DD-MM-YYYY）和数值分隔符（小数点或逗号）。这种格式差异在数据合并和计算时可能会产生误解，特别是涉及国际数据时。

- **区域配置**：
  - 例如，美国的数据以 `MM-DD-YYYY` 表示日期，且小数点符号为 `.`，而欧洲国家使用 `DD-MM-YYYY` 和 `,` 分隔小数。
  - 在读取数据时，可以使用 `decimal` 和 `thousands` 参数解决小数点和千分位符问题。

**示例代码**：
```python
# 读取文件时指定小数点和千分位符
df = pd.read_csv('data.csv', decimal=',', thousands='.')
```

- **人工录入错误**：
  - 在数据录入过程中，可能会有拼写错误或格式不一致的情况。可以生成频次表，检查常见的拼写错误或分类变量中的异常值。

**生成频次表检查拼写错误**：
```python
# 查看分类字段的频次
print(df['regime_type'].value_counts())
```

- **缺失值表示**：数据集中缺失值表示方式不统一时，可能使用“NaN”、“N/A”、“-”等不同表示。可以使用 `na_values` 参数将不同的缺失值表示统一为 NaN。

**示例代码**：
```python
# 将“NA”、“N/A”视为缺失值
df = pd.read_csv('data.csv', na_values=['N/A', 'NA', '-'])
```

#### 4. 数据结构标准化

确保数据唯一性和列名的一致性对于数据分析的结构化和代码复用非常重要。

- **唯一标识符**：每条记录应具有唯一标识符，确保数据无重复。唯一标识可以是单一字段（如 ID），或组合字段（如国家+年份）。
- **列名标准化**：列名应简洁易读，无空格，并使用小写字母和下划线，以便于引用和自动化处理。

**代码示例**：
```python
# 检查并删除重复行
print("重复行数量：", df.duplicated().sum())
df = df.drop_duplicates()

# 标准化列名
df.columns = [col.replace(" ", "_").lower() for col in df.columns]
```

---

### 数据内容清理

#### 1. 数据类型转换：字符串与数值

有时数值可能会带有千分位符或货币符号，导致其被误读为字符串，需要移除这些符号并将其转换为数值格式。

**代码示例**：
```python
# 移除千分位符或货币符号，并转换为浮点数
df['amount'] = df['amount'].replace('[\$,]', '', regex=True).astype(float)
```

#### 2. 特殊字符处理

确保数据中的字符干净一致，避免因为多余字符导致误读。例如，移除货币符号、单位符号等。

- **去除前后空格**：使用 `strip()` 去除字符串首尾空格。
- **移除特定字符**：使用 `replace()` 去除多余字符，例如百分号 `%`。

**示例代码**：
```python
# 去除空格和特定符号
df['city'] = df['city'].str.strip()
df['percentage'] = df['percentage'].str.replace('%', '').astype(float)
```

#### 3. 分类数据与频次检查

生成频次表以检查分类数据的拼写一致性。例如，检查字段 `regime_type` 是否有拼写错误（如“demcracy”）。

**示例代码**：
```python
# 生成分类变量的频次表
print(df['regime_type'].value_counts())
```

#### 4. 处理缺失值

缺失值可以通过多种方法处理，如删除包含缺失值的行、用均值填充或插值法处理。

**示例代码**：
```python
# 删除包含缺失值的行
df = df.dropna()

# 使用列的平均值填充缺失值
df['column_name'] = df['column_name'].fillna(df['column_name'].mean())
```

---

### 数据清理中的高级操作

#### 1. 字符串处理函数

- **分列**：将字符串分为多列时可以使用 `split()`，例如将“城市, 国家”分为两个字段。

**示例代码**：
```python
# 使用逗号将城市和国家分为两列
df[['city', 'country']] = df['location'].str.split(',', expand=True)
```

#### 2. 正则表达式

正则表达式用于识别特定模式的字符，如非数字字符或特定格式。可以利用正则表达式替换或提取所需的字符串。

**示例代码**：
```python
import re

# 去除非数字字符
df['numeric_column'] = df['numeric_column'].apply(lambda x: re.sub(r'\D', '', x))
```

#### 3. 提取和替换

可以使用 `replace()` 替换多余字符，或 `str.extract()` 提取特定子字符串。

**示例代码**：
```python
# 替换符号
df['text_column'] = df['text_column'].str.replace('$', '')

# 提取子字符串（年份）
df['year'] = df['date_column'].str.extract(r'(\d{4})')
```

---

### 数据格式化

#### 日期格式转换

日期格式应当统一，避免在不同国家或数据库系统中的误读。

**代码示例**：
```python
# 将日期转换为 YYYY-MM-DD 格式
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')
```

#### 数值格式

处理

确保数值字段不含多余符号，如货币符号、百分比符号，确保格式一致。

**代码示例**：
```python
# 去除百分号并转换为数值
df['growth_rate'] = df['growth_rate'].str.replace('%', '').astype(float) / 100
```

---

### 高级清理任务与技巧

#### 数据验证与一致性检查

在完成清理后，进行数据验证非常重要。可以使用统计方法检查字段的均值、标准差、最大值和最小值，确保数据的合理性。

**代码示例**：
```python
# 数据描述统计
print(df.describe())

# 检查某列的唯一值
print(df['column_name'].unique())
```

#### 可重复代码的模块化

对于复杂的清理任务，建议将代码封装成函数，以便于在多个数据集中重复使用。

**代码示例：将清理步骤封装为函数**：
```python
def clean_column(data, column_name):
    data[column_name] = data[column_name].str.replace('$', '').astype(float)
    data[column_name] = data[column_name].fillna(data[column_name].mean())
    return data
```

---

### 总结

系统化的数据清理流程包括初步检查、标准化、内容清理、格式转换和数据验证等步骤。在确保数据一致性和完整性的前提下，可以提高分析的准确性和模型的表现。掌握数据清理工具和技巧，研究生们可以高效地完成数据处理任务，为后续分析提供优质数据。