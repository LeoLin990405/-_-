# **重采样方法、交叉验证与模型评估：研究生自学详细笔记**  

---

**日期**：2024年10月30日  
**讲师**：Simon Hoellerbauer  
**目标**：详细推导 **交叉验证（Cross Validation）** 和 **自助法（Bootstrapping）** 的数学公式与算法流程，结合代码实现与应用场景，帮助学生理解如何通过这些方法提升模型评估的稳定性和泛化能力。

---

## 1. **重采样方法的背景与目标**

在机器学习中，我们的目标是**构建一个泛化良好的模型**，即在**未见数据**上也能保持良好的性能。然而，单次的 **训练集-测试集划分（train-test split）** 存在如下问题：  
1. **数据浪费**：部分数据仅用于测试，未能参与训练。  
2. **性能评估不稳定**：评估结果依赖于特定的测试集划分，易引入误差。  
3. **超参数调优受限**：如果模型在测试集上表现较差，难以判断是超参数选择错误还是划分导致。

为了解决这些问题，我们需要通过 **重采样方法（Resampling Methods）** 提升模型的稳定性和可靠性。

---

## 2. **交叉验证（Cross Validation）**

### 2.1 **K 折交叉验证（K-Fold Cross Validation）**

**K 折交叉验证**是一种通过将数据集划分为 $K$ 份（**folds**），并多次训练和测试模型来减少偶然性误差的技术。

---

### **公式推导**  

假设数据集为 $D = \{x_1, x_2, \dots, x_N\}$，其中 $N$ 为样本总数。将数据集划分为 $K$ 个子集 $\{D_1, D_2, \dots, D_K\}$，每个子集的大小约为 $n_i = \frac{N}{K}$。  

对于第 $i$ 轮交叉验证，我们用 $\{D_1, \dots, D_{i-1}, D_{i+1}, \dots, D_K\}$ 作为训练集，用 $D_i$ 作为测试集。**第 $i$ 轮的损失函数**为：  
$$
L_i = \frac{1}{n_i} \sum_{j=1}^{n_i} \ell\left( y_j, \hat{y}_j \right)
$$
其中：  
- $\ell(y_j, \hat{y}_j)$ 是损失函数，如均方误差（MSE）。  
- $n_i$ 是测试集中样本的数量。  

**总体交叉验证误差**为 $K$ 次测试误差的平均值：  
$$
L_{\text{CV}} = \frac{1}{K} \sum_{i=1}^K L_i
$$

---

### 2.2 **K 折交叉验证的流程**  

1. **将数据集划分为 $K$ 个子集**。  
2. **重复 $K$ 次**：  
   - 在每一轮中，选择一个子集作为**测试集**，其余 $K-1$ 个子集作为**训练集**。  
   - 使用训练集拟合模型，并在测试集上评估误差。  
3. **计算所有折误差的平均值**，作为模型的整体性能。

---

### 2.3 **交叉验证的特殊形式**

#### **Leave-One-Out Cross Validation (LOOCV)**  
- **流程**：将数据集划分为 $N$ 份，每次仅使用一个样本作为测试集，其余样本作为训练集。  
- **公式**：  
  $$
  L_{\text{LOOCV}} = \frac{1}{N} \sum_{i=1}^N \ell\left( y_i, \hat{y}_i \right)
  $$
- **优点**：最大化训练数据的使用。  
- **缺点**：计算成本极高。

---

### 2.4 **Python 实现 K 折交叉验证**

```python
from sklearn.model_selection import KFold, cross_validate
from sklearn.linear_model import LogisticRegression

# 数据准备
X, y = ...

# 定义 K 折交叉验证对象（K=10）
kf = KFold(n_splits=10, shuffle=True, random_state=42)

# 定义逻辑回归模型
model = LogisticRegression()

# 执行交叉验证并评估性能
cv_results = cross_validate(model, X, y, cv=kf, scoring=['accuracy', 'f1', 'roc_auc'])

# 打印每折结果和平均准确率
print("每折准确率：", cv_results['test_accuracy'])
print("平均准确率：", cv_results['test_accuracy'].mean())
```

---

### 2.5 **交叉验证的优缺点**

**优点**：
- **高效利用数据**：每个样本都至少一次作为测试集。  
- **减少过拟合**：模型不依赖于特定的训练/测试划分。  
- **适用于小数据集**：相比一次性划分，结果更稳定。  

**缺点**：
- **计算成本高**：需要训练 $K$ 个模型。  
- **数据依赖性较强**：不同折的误差可能有波动。  

---

## 3. **自助法（Bootstrapping）**

### 3.1 **自助法的原理**  

自助法是一种 **有放回抽样** 技术，从原始数据集中多次抽取样本生成新的数据集，用于**估计模型参数的不确定性**。

---

### 3.2 **数学推导**

#### **抽样过程**  
给定数据集 $D = \{x_1, x_2, \dots, x_N\}$，每次有放回地抽取 $N$ 个样本生成一个自助样本 $D^*$。

#### **未被抽中样本的概率**  
在一次采样中，任意样本 $x_i$ **未被选中的概率**为：  
$$
\text{Pr}(x_i \text{ 未被选中}) = 1 - \frac{1}{N}
$$
经过 $N$ 次抽样后，该样本未被选中的概率为：  
$$
\left(1 - \frac{1}{N}\right)^N \approx \frac{1}{e} \approx 0.368
$$
这意味着，在每个自助样本中，大约有 $36.8\%$ 的样本不会出现。

#### **标准误差的估计**  
对于某个统计量 $\theta$（如均值），生成 $B$ 个自助样本，每个样本计算出 $\theta^*_b$。**标准误差**估计为：  
$$
\hat{\sigma}_{\theta} = \sqrt{\frac{1}{B} \sum_{b=1}^B \left( \theta^*_b - \bar{\theta}^* \right)^2}
$$
其中 $\bar{\theta}^* = \frac{1}{B} \sum_{b=1}^B \theta^*_b$。

---

### 3.3 **Python 实现自助法**

```python
import numpy as np
from sklearn.utils import resample
from sklearn.linear_model import LogisticRegression

# 数据准备
X, y = ...

# 创建自助样本
X_bootstrap, y_bootstrap = resample(X, y, n_samples=len(X), replace=True)

# 用自助样本训练模型
model = LogisticRegression()
model.fit(X_bootstrap, y_bootstrap)

# 在原始数据上评估模型性能
accuracy = model.score(X, y)
print(f"自助法模型准确率：{accuracy}")
```

---

## 4. **模型评估指标及公式**

### 4.1 **准确率 (Accuracy)**  
$  
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}  
$

### 4.2 **精确率 (Precision)**  
$  
\text{Precision} = \frac{TP}{TP + FP}  
$

### 4.3 **召回率 (Recall)**  
$  
\text{Recall} = \frac{TP}{TP + FN}  
$

### 4.4 **F1 分数 (F1 Score)**  
$  
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}  
$

---

## 5. **总结与思考**

1. **交叉验证与自助法的互补性**：交叉验证用于模型评估，自助法用于不确定性估计。  
2. **选择合适的性能指标**：根据具体任务选择准确率、F1 分数或 AUC 等指标。  
3. **计算效率优化**：大数据集

上采用分布式计算，或减少交叉验证的折数。

---

本笔记详细介绍了交叉验证和自助法的**原理、公式推导与代码实现**，为研究生深入理解模型评估与优化奠定了坚实基础。