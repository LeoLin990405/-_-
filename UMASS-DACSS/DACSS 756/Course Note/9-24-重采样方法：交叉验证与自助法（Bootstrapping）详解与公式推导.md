## **重采样方法：交叉验证与自助法（Bootstrapping）详解与公式推导**

---

## **1. 引言：模型评估的必要性与重采样的引入**

在机器学习与统计建模中，**评估模型的泛化能力**至关重要，即判断模型在**未见数据**上的表现是否足够稳定和准确。泛化能力通过**测试误差（Test Error）**来衡量，但由于无法获取所有未来数据，我们只能基于现有样本进行测试误差的估计。

### **1.1 模型误差的基本类型**

1. **训练误差（Training Error）：**  
   $  
   \text{Training Error} = \frac{1}{N} \sum_{i=1}^{N} \left( y_i - \hat{f}(x_i) \right)^2  
   $

   训练误差衡量模型在训练集上的表现。虽然训练误差低可能说明模型在已知数据上拟合良好，但它无法反映模型对未知数据的预测能力。

2. **测试误差（Test Error）：**  
   **测试误差**是模型在未见数据上的平均预测误差，用于衡量模型的**泛化性能**：

   $$
   \text{Test Error} = \mathbb{E}\left[(Y - \hat{f}(X))^2\right]
   $$

   其中，$(X, Y)$ 是来自真实分布的未知数据点，$\hat{f}(X)$ 是模型对 $X$ 的预测值。

### **1.2 模型评估的核心挑战**

- **未见数据无法获得**：只能通过现有数据的划分或重采样来估计测试误差。
- **偏差-方差权衡（Bias-Variance Tradeoff）**：
  - **偏差（Bias）：** 模型预测值与真实值之间的系统性误差。
  - **方差（Variance）：** 不同数据划分或样本导致模型输出的波动性。

为了解决这些问题，我们引入了**重采样方法（Resampling Methods）**：**交叉验证（Cross-Validation）** 和 **自助法（Bootstrapping）**。

---

## **2. 训练-测试集划分法（Train-Test Split）**

#### **方法概述**
- 数据集 $\mathcal{D}$ 划分为：
  1. **训练集（Training Set）：** 用于训练模型 $\hat{f}(x)$。
  2. **测试集（Test Set）：** 用于评估模型性能，估计测试误差。

#### **测试误差的估计公式**

$$
\text{Test Error Estimate} = \frac{1}{|\mathcal{D}_{\text{test}}|} \sum_{i \in \mathcal{D}_{\text{test}}} \left( y_i - \hat{f}(x_i) \right)^2
$$

### **优缺点分析**
- **优点：** 简单直观，适用于初步模型评估。
- **缺点：**
  1. **高方差**：不同划分会导致测试误差估计不稳定。
  2. **数据利用不足**：部分数据仅用于测试而未参与训练，特别是当数据量较小时表现较差。

---

## **3. K 折交叉验证 (K-Fold Cross-Validation) 详解与公式推导**

### **3.1 K 折交叉验证的基本流程**

**K 折交叉验证**将数据集划分为 $K$ 个**大小相近的子集（folds）**，逐次使用一个子集作为**验证集**，其余 $K-1$ 个子集作为**训练集**，通过多次训练与验证来减少估计误差的方差。

#### **具体流程**
1. 将数据集 $\mathcal{D}$ 随机划分为 $K$ 个不重叠的子集：
   $\mathcal{D}_1, \mathcal{D}_2, \dots, \mathcal{D}_K$。
2. 对于第 $k$ 次迭代：
   - 使用 $K-1$ 个子集作为训练集，拟合模型 $\hat{f}^{(-k)}(x)$。
   - 用第 $k$ 个子集作为验证集，计算误差：

     $$
     \text{Validation Error}_k = \frac{1}{|\mathcal{D}_k|} \sum_{i \in \mathcal{D}_k} \left( y_i - \hat{f}^{(-k)}(x_i) \right)^2
     $$

3. **所有折的平均验证误差**作为最终测试误差的估计：

   $$
   \text{CV Error} = \frac{1}{K} \sum_{k=1}^{K} \text{Validation Error}_k
   $$

---

### **3.2 K 值的选择与影响**

- **K = 5 或 K = 10** 是常见选择，计算成本适中且估计结果稳定。
- **极端情况：留一法（LOOCV）**：
  - 每次仅留一个数据点作为验证集，其余 $N-1$ 个数据点用于训练。
  - **公式：**

    $$
    \text{LOOCV Error} = \frac{1}{N} \sum_{i=1}^{N} \left( y_i - \hat{f}^{(-i)}(x_i) \right)^2
    $$

#### **K 的选择与偏差-方差权衡**
- **较小的 K 值**（如 5）：训练集较大，估计的**偏差较小**但**方差较高**。
- **较大的 K 值**（如 LOOCV）：方差较低，但计算成本显著增加。

---

### **3.3 嵌套交叉验证（Nested Cross-Validation）**

嵌套交叉验证用于**超参数调优（Hyperparameter Tuning）**与模型评估，避免**数据泄露（Data Leakage）**。

#### **嵌套交叉验证流程**
1. **外层交叉验证**用于评估模型的最终性能。
2. **内层交叉验证**用于选择最佳超参数 $\lambda$：

   $$
   \lambda^* = \arg\min_\lambda \frac{1}{K_{\text{inner}}} \sum_{j=1}^{K_{\text{inner}}} \text{Validation Error}_j(\lambda)
   $$

3. 使用选定的 $\lambda^*$ 训练模型，并在外层验证集上评估：

   $$
   \text{Test Error}_k = \frac{1}{|\mathcal{D}_k|} \sum_{i \in \mathcal{D}_k} \left( y_i - \hat{f}_{\lambda^*}^{(-k)}(x_i) \right)^2
   $$

---

## **4. 自助法（Bootstrapping）详解与公式推导**

### **4.1 自助法的基本概念**

自助法是一种**有放回的重采样**方法，用于估计**统计量的分布**。在样本量较小且无法假设特定数据分布的情况下，自助法提供了有效的非参数估计。

---

### **4.2 自助法的步骤与公式**

1. 从原始数据 $\mathcal{D} = \{(x_1, y_1), \dots, (x_N, y_N)\}$ 中**有放回地抽样**，生成自助样本 $\mathcal{D}^*$。
2. 在自助样本上计算感兴趣的统计量（如均值、回归系数），记为 $\theta^*$。
3. 重复上述过程 $B$ 次，得到 $B$ 个统计量：  
   $\{\theta_1^*, \theta_2^*, \dots, \theta_B^*\}$。
4. 构建统计量的 **95% 置信区间（CI）**：

   $$
   \left[ \theta^*_{\lfloor 0.025B \rfloor}, \theta^*_{\lfloor 0.975B \rfloor} \right]
   $$

---

## **5. 交叉验证与自助法的对比与总结**

| **方法**     | **用途**                      | **优点**                     | **缺点**                 |
| ------------ | ----------------------------- | ---------------------------- | ------------------------ |
| K 折交叉验证 | 评估测试误差 & 调优超参数     | 减少方差，充分利用数据       | 增加计算成本             |
| 自助法       | 估计统计量分布 & 计算置信区间 | 无需分布假设，适用于复杂模型 | 重采样次数多时计算成本高 |

---

## **6. 总结与建议**

- **交叉验证**：适用于**模型评估**与**超参数调优**，推荐使用 **K = 5 或 K = 10**。

- **嵌套交叉验证**：用于复杂模型调优，避免数据泄露。
- **自助法**：适用于估计**统计量的分布及不确定性**，特别是在无法假设分布或数据量较小时。

通过合理使用这些重采样方法，我们可以有效提升模型的评估可靠性，并准确量化模型预测的不确定性。