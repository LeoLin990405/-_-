# **分类模型与评估：详细笔记（适合研究生自学）**  
_授课时间：2024年10月30日_

---

## **目录**  
1. [分类模型与回归模型的区别](#1-分类模型与回归模型的区别)  
2. [分类模型评估指标与公式详细推导](#2-分类模型评估指标与公式详细推导)  
3. [Python 实现：Logistic 回归与 ROC 曲线](#3-python-实现-logistic-回归与-roc-曲线)  
4. [R 实现：QDA 模型与 Tidy Models](#4-r-实现-qda-模型与-tidy-models)  
5. [ROC 曲线与 AUC 指标的数学推导](#5-roc-曲线与-auc-指标的数学推导)  
6. [模型评估中的权衡与指标选择](#6-模型评估中的权衡与指标选择)  
7. [练习任务与作业提醒](#7-练习任务与作业提醒)  

---

## **1. 分类模型与回归模型的区别**

### **1.1 回归模型**  
回归模型用于预测**连续值**，例如预测房价或温度。其目标是最小化预测值与实际值之间的误差，常用的误差度量包括：

- **均方误差 (MSE)**：  
$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$
其中，$y_i$ 是第 $i$ 个样本的真实值，$\hat{y}_i$ 是预测值。

- **平均绝对误差 (MAE)**：  
$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

---

### **1.2 分类模型**  
分类模型用于预测**离散类别标签**，如预测邮件是否为垃圾邮件，或学生是否被录取。其错误类型比回归问题复杂，涉及：  

- **假阳性 (FP)**：负类样本被错误预测为正类。  
- **假阴性 (FN)**：正类样本被错误预测为负类。  

---

## **2. 分类模型评估指标与公式详细推导**

### **2.1 混淆矩阵 (Confusion Matrix)**  

混淆矩阵展示了模型的预测结果与真实值之间的对应关系：

|              | **实际为正** | **实际为负** |
| ------------ | ------------ | ------------ |
| **预测为正** | 真阳性 (TP)  | 假阳性 (FP)  |
| **预测为负** | 假阴性 (FN)  | 真阴性 (TN)  |

---

### **2.2 准确率 (Accuracy)**  
准确率衡量了所有预测正确的样本所占比例：  

$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$

**优缺点**：  
- 优点：适用于类别均衡的数据。  
- 缺点：在类别不平衡的数据集上效果不佳。例如，如果 90% 的样本属于负类，即使模型全部预测为负类，也会有 90% 的准确率，但模型无法识别正类。

---

### **2.3 精确率 (Precision)**  
精确率衡量所有被预测为正类的样本中，实际为正类的比例：  

$$
Precision = \frac{TP}{TP + FP}
$$

- **高精确率**适用于需要减少假阳性的场景，如疾病筛查中避免误诊。  

---

### **2.4 召回率 (Recall)**  
召回率衡量所有实际为正类的样本中，被正确预测为正类的比例：  

$$
Recall = \frac{TP}{TP + FN}
$$

- **高召回率**适用于减少假阴性的重要场景，如肿瘤筛查，确保所有阳性病例都能被识别。

---

### **2.5 F1 分数 (F1 Score)**  
F1 分数是精确率和召回率的调和平均数，常用于**不平衡数据集**：

$$
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
$$

- F1 分数在精确率和召回率之间取得平衡，当我们希望避免偏向某一个指标时非常有用。

---

### **2.6 假阳性率 (FPR) 和 真阳性率 (TPR)**  
- **假阳性率 (FPR)**：  

$$
FPR = \frac{FP}{FP + TN}
$$

- **真阳性率 (TPR)**（即召回率）：  

$$
TPR = \frac{TP}{TP + FN}
$$

这些指标用于绘制**ROC 曲线**，帮助我们评估模型的性能。

---

## **3. Python 实现：Logistic 回归与 ROC 曲线**

### **3.1 代码实现**

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# 数据加载与划分
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Logistic 回归模型训练
model = LogisticRegression()
model.fit(X_train, y_train)

# 模型预测与概率输出
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# 混淆矩阵与评估指标
conf_matrix = confusion_matrix(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_prob)

print(f"Confusion Matrix:\n{conf_matrix}")
print(f"Accuracy: {accuracy}")
print(f"ROC-AUC: {roc_auc}")

# 绘制 ROC 曲线
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.plot(fpr, tpr, label='ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
```

---

## **4. R 实现：QDA 模型与 Tidy Models**

### **4.1 代码实现**

```r
library(tidymodels)
library(discrim)

# 数据准备
data <- read.csv("admissions.csv")
data$admit <- as.factor(data$admit)

# 数据集划分
set.seed(42)
split <- initial_split(data, prop = 0.7)
train_data <- training(split)
test_data <- testing(split)

# 构建 QDA 模型并训练
qda_model <- discrim_quad() %>%
  set_engine("MASS") %>%
  set_mode("classification")

qda_workflow <- workflow() %>%
  add_model(qda_model) %>%
  add_formula(admit ~ .) %>%
  fit(data = train_data)

# 预测与评估
predictions <- predict(qda_workflow, test_data, type = "prob")
roc_auc(predictions, truth = test_data$admit, .pred_1)
```

---

## **5. ROC 曲线与 AUC 指标的数学推导**

### **5.1 ROC 曲线的定义**

ROC 曲线（Receiver Operating Characteristic Curve）展示模型在不同阈值下的**假阳性率 (FPR)** 与**真阳性率 (TPR)** 之间的权衡关系。  

### **5.2 AUC 的数学表达**  

AUC（Area Under the Curve）表示 ROC 曲线下的面积，用于衡量模型在所有阈值下的整体性能：

$$
AUC = \int_0^1 TPR(FPR) \, d(FPR)
$$

- **AUC = 1**：模型完美区分正负样本。  
- **AUC = 0.5**：模型效果与随机猜测相同。  
- **AUC < 0.5**：模型表现甚至不如随机猜测。

---

## **6. 模型评估中的权衡与指标选择**

### **6.1 指标选择的挑战**  
- **准确率**适用于类别分布均衡的数据集。  
- **F1 分数**更适合于类别不平衡的场景。  
- **ROC-AUC**用于评估模型在不同阈值下的整体性能。

### **6.2 应用场景的权衡**  
在实际应用中，我们需要根据具体任务的需求选择合适的指标。例如：
- 在医疗诊断中，更注重**召回率**，以减少漏诊。  
- 在垃圾邮件过滤中，更关注**精确率**，以减少误判。

---

## **7. 练习任务与作业提醒**

### **7.1 练习任务**  
1. 使用 Python 或 R 实现两个分类模型（如 Logistic 回归与 QDA），并比较它们的表现。  

2. 使用**混淆矩阵、F1 分数和 ROC-AUC** 分析模型的优劣。

### **7.2 作业提醒**  
- **项目提案**于明天截止，请按时提交。  
- 下节课将讨论**交叉验证与模型优化**。

---

**总结**：  
本次课程详细介绍了分类模型的构建与评估，并通过 Python 和 R 的代码示例展示了如何应用不同模型。理解不同评估指标的适用场景与选择方法对于优化模型性能至关重要。