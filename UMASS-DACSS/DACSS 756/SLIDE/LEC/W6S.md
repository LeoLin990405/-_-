### 聚类技术概述

#### 聚类的定义和目标
- **聚类**是一种强大的方法，用于将数据点或观测值分组为称为**簇**的子组。目标是识别数据中的自然分组，使得每个组内的观测值具有相似性，而与其他组尽可能不同。
- 聚类的主要**目标**是找到数据集的划分，使每个子组（簇）中的观测值是同质的或根据某些标准具有高度相似性。这种技术是无监督的，意味着我们没有预定义的每个观测值的标签。
- 应用聚类时，必须定义观测值之间的**相似性或差异性度量**。常用的度量包括**欧氏距离**和**曼哈顿距离**等。选择合适的相似性度量通常需要领域的实质性知识，以确保分组具有意义。

#### 聚类方法的类型
聚类可以大致分为多种方法，每种方法都有其自身的特点和应用。在本节中，我们将讨论两种最常见的聚类技术：**K均值聚类**和**层次聚类**。

### 1. K均值聚类

#### 概述
- **K均值聚类**是一种用于将数据集中的观测值划分为预定数量簇（记为`K`）的方法。它旨在最小化每个簇内的变化，同时确保簇之间的差异尽可能大。
- 在K均值聚类中，我们关注的是最小化**簇内变异（WCV）**，这是衡量簇内观测值相似性的一种方法。

#### 目标函数
- K均值聚类的主要目标是将观测值划分为`K`个簇，使得所有簇的**总簇内变异**最小化。其优化问题可以表示为：
  
$$
\min_{C_1, \dots, C_K} \sum_{k=1}^{K} \text{WCV}(C_k) = \min_{C_1, \dots, C_K} \sum_{k=1}^{K} \sum_{i, i' \in C_k} \| x_i - x_{i'} \|^2
$$

  其中：
  - $ C_k $ 表示分配给簇 $ k $ 的观测值集合。
  - $ \| x_i - x_{i'} \| $ 表示观测值 $ x_i $ 和 $ x_{i'} $ 之间的距离（通常是欧氏距离）。

#### 算法步骤
1. **初始化**：随机为每个观测值分配一个从1到`K`的编号，表示初始簇分配。
2. **迭代**：重复以下步骤直至收敛（即簇分配不再变化）：
   - **质心计算**：对于每个簇，计算其**质心**（即该簇中观测值特征的平均向量）。
   - **重新分配**：将每个观测值分配给与其质心**最近**的簇，距离通常使用**欧氏距离**定义。

#### K均值算法的性质
- **收敛性**：该算法保证每一步都会减少目标函数的值，从而导致收敛。然而，**不保证找到全局最小值**，结果可能取决于初始簇分配。
- **Scree图**：为了确定最佳的簇数（`K`），可以使用**Scree图**。该图显示了不同`K`值下的**惯性**（总簇内变异）。"肘部点"通常被认为是理想的簇数，因为它代表了最小化簇内变异和避免过拟合之间的平衡。

#### 代码示例（Python）
```python
from sklearn.cluster import KMeans
import numpy as np
import matplotlib.pyplot as plt

# 示例数据
X = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])

# 创建KMeans对象并进行拟合
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)

# 获取簇分配和质心
labels = kmeans.labels_
centroids = kmeans.cluster_centers_

# 可视化簇分配
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='red', marker='X')
plt.show()
```

### 2. 层次聚类

#### 概述
- 与K均值不同，**层次聚类**不需要预先指定簇的数量。相反，它生成一个称为**树状图（dendrogram）**的树形表示，用于可视化不同层次的簇形成。
- **层次聚类**可以是**自底向上（聚合型）**或**自顶向下（分裂型）**。最常见的是**聚合型**，即每个观测值开始时各自为一个簇，然后逐步合并，直到所有观测值合并为一个簇。

#### 算法步骤（聚合型聚类）
1. **初始化**：每个观测值各自成为一个簇。
2. **合并最近的簇**：在每一步，识别彼此最近的两个簇并将它们合并为一个簇。
3. **重复**，直到所有观测值合并为一个簇。
4. **树状图构建**：合并过程用**树状图**表示，显示合并的顺序，并帮助可视化不同层次的簇。

#### 连接准则
在层次聚类中，重要的是决定如何测量**簇之间的距离**，这称为**连接准则**。一些常见的连接方法包括：
- **单链接**：两个簇之间的距离定义为这两个簇中任意两个点之间的最短距离。
- **全链接**：两个簇之间的距离定义为这两个簇中任意两个点之间的最长距离。
- **平均链接**：两个簇之间的距离定义为这两个簇中所有点对之间的平均距离。

#### 代码示例（Python）
```python
from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt
import numpy as np

# 示例数据
X = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])

# 使用层次聚类的聚合链接方法
Z = linkage(X, 'ward')

# 绘制树状图
dendrogram(Z)
plt.show()
```

### 聚类中的实际考虑因素

#### 变量的缩放与标准化
- **变量的缩放**：在聚类中，变量的缩放会显著影响结果，特别是在使用基于距离的度量（如欧氏距离）时。为了确保所有特征对聚类过程的贡献相同，通常建议对变量进行**标准化**，即使其均值为零、方差为一。

#### 选择簇的数量
- **K均值聚类**：需要用户提前指定簇的数量（`K`）。可以使用**Scree图**或**轮廓图（silhouette plot）**等可视化工具来帮助确定最佳簇数。
- **层次聚类**：不需要预先指定簇的数量，但必须在某个层次**截断树状图**以获得有用的聚类结果。此决定也可以通过Scree图或轮廓图来指导，但没有统一的标准方法。

### 聚类应用示例

#### 示例 1: Garcia, Pineault, 和 Bryfonski (2023)
- 该研究使用了包含**五个特征**的**K均值聚类**方法来对观测值进行分组。
- 分析包括识别**簇的质心**（每个簇中特征的平均值）并基于这些质心解释每个簇的性质。

#### 示例 2: Hoellerbauer (2024)
- 使用了不同的聚类方法，即**混合模型（mixture models）**。混合模型是一种**参数聚类**方法，其中每个簇由一个统计分布（如高斯分布）表示。
- **概率方法**使得混合模型的聚类更灵活，因为观测值可以以一定概率属于多个簇。

### 重要概念总结

1. **聚类**旨在通过最小化簇内差异和最大化簇间差异来找到数据中的自然分组。
2. **K均值聚类**是一种分区方法，需要预定义簇的数量，并使用迭代方法最小化簇内方差。
3. **层次聚类**通过自底向上或自顶向下的方法构建簇的树状图，不需要预定义簇的数量。
4. **连接准则**和**差异度量**在确定层次聚类的质量方面起着关键作用。
5. **缩放和标准化**对于确保聚类结果具有意义至关重要，特别是对于基于距离的度量。

### 关键要点
- **K均值**和**层次聚类**各有优缺点。K均值高效，但需要预定义`K`；而层次聚类提供了无需预定义`K`的全面视角。
- **实际考虑因素**，如数据标准化、距离度量的选择和连接准则的选择，会显著影响聚类的结果。
- 使用**可视化工具**如树状图和Scree图对于有效解释和验证聚类结果非常重要。

